# Fossee-python-task

## Research Plan
During my research, I explored about various open source models and LLMs such as StarCoder, WizardCoder, Mistral and recently released models like Qwen2.5-Coder, CodeLlama, and DeepSeek Coder v3. Out of all these models, I shortlisted the following models Qwen2.5-Coder, CodeLlama, and DeepSeek Coder v3 for comparison analysis. Qwen2.5-Coder provides multilingual and multiple programming language coding capabilities, CodeLlama benefits from itâ€™s Python focused variant and large user community. Whereas DeepSeek Coder v3 proved to be the most balanced option out of these models for competence analysis in Python. It is is trained over 2 trillion tokens of high-quality code and explanations, and released in multiple instruct-tuned sizes (1.3B, 6.7B, and 33B), it also shows benchmark results on HumanEval and MBPP that consistently surpasses other models. Its main ability is its flexible scaling: the 6.7B Instruct model is efficient enough to run locally on modest GPUs while still outperforming CodeLlama-13B, whereas the 33B model can be deployed if higher throughput or broader coverage is required. This ensures that the model can be tuned to fit the system capacity and the educational use case without compromising accuracy or cost.

To test DeepSeek Coder v3, I verified its technical capabilities in detail. For analyzing student Python code, its code-heavy pretraining allows the model to understand interpret logical flows, data structure misuse, and non syntactic errors. The Instruct fine-tuning allows it to produce probing, Socratic-style questions that evaluate comprehension rather than providing the full solutions directly. Its strong code benchmarks can be used to identify misconceptions and reasoning gaps, such as finding missing base cases in recursion or loop errors. Lastly, to check the practicality, I implemented a prototype in order to test these behaviours on student code. In conclusion, after an extensive technical analysis, benchmark comparisons on the model and validating the practicality through my prototype, these factors reassured me to confidently state that DeepSeek Coder v3 stands out as the most optimal and well-suited model for our use case. Its balance of accuracy, efficiency, and adaptability makes it not just theoretically strong but also practically reliable for high-level student competence analysis in Python.
## Benchmarks
## Prototype
## References
